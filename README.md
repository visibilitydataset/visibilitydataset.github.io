# ViVID++ : Vision for Visibility Dataset

In this work, we present a dataset for developing robust visual SLAM in the real world by providing:
- the first dataset to enclose information from multiple types of synchronized alternative vision sensors;
- multi-sensory measurements with ground-truth from external positioning system and generated from SLAM;
- wide range of environments in indoor and outdoor, recorded from multiple platforms.

## Keywords

Data Sets for SLAM; Data Sets for Robotic Vision; Data Sets for Robot Learning

## Overview

<div class="t3iYD" style="text-align: center;">
  <img class="CENy8b" role="img" src="https://urserver.kaist.ac.kr/publicdata/ViViD++/figures/visibility.png" width="75%" height="auto" />
</div>

 An overview of the sensor system and the dataset. We set up different sensor configurations for handheld (upper left) and driving (upper right). Sensor systems include RGB, thermal, events, depth, and interial measurements. Each sensor is indicated with the letter box. Each sensor's visibility differences are displayed in the lower row. Relative to RGB, thermal and event show less variance to the illumination condition.

 <div class="t3iYD" style="text-align: center;">
 <video width="640" height="360" controls>
   <source src="https://urserver.kaist.ac.kr/publicdata/ViViD++/RAL2021-video-main.mp4" type="video/mp4">
 </video>
</div>

## The Dataset

{% include list.liquid all=true %}

## Website License
<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
